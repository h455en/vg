name: Run Sky Scrap

# Define the events that trigger this workflow (schedule and manual)
on:
  schedule:
    # Runs every day at 08:00 UTC
    - cron: "0 8 * * *"
  # Allows manual run from the Actions tab in the GitHub UI
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest

    # Inject the GIST token from the repository secrets into the environment
    env:
      GITHUB_TOKEN: ${{ secrets.GH_PAT_GIST }}

    steps:
      # Step 1: Checkout repository files
      - name: Checkout Repository
        uses: actions/checkout@v4

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          
      # Step 3: Install Python dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          # Installing required libraries: requests, beautifulsoup4, and playwright
          pip install requests beautifulsoup4 playwright

      # Step 4: Install Playwright browsers
      - name: Install Playwright Browsers
        # Install the Chromium browser binary required for headless scraping
        run: playwright install chromium

      # Step 5: Execute the main script
      - name: Run Gist Scraper Script
        # Executes the script which reads the GITHUB_TOKEN environment variable
        run: python skyscra.py
